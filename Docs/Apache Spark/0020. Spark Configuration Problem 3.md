## I have 10 partitions. I want to assign cpu cores. How many cores would I need?

---

### âœ… Spark Execution Principle:

* Spark runs **one task per partition**, and **one task per core at a time**.
* So, **number of concurrent cores = number of parallel tasks = number of partitions (max)**

---

### ðŸ”¢ Your Scenario:

* **10 partitions** â‡’ **10 tasks**
* To run **all 10 tasks in parallel**, you need:

  ```
  âœ… 10 CPU cores
  ```

---

### ðŸ”„ Optional Alternatives:

* If you allocate **fewer than 10 cores** (say, 5), Spark will:

  * Run 5 tasks in parallel
  * Then run the next 5 (in 2 waves)
  * **Total execution time increases**

---

### ðŸ“Œ Summary:

| Partitions | CPU Cores Needed (for max parallelism) |
| ---------- | -------------------------------------- |
| 10         | **10 cores**                           |
