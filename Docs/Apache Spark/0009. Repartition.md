## 🔄 What is `repartition()` in Spark?

In Apache Spark, **`repartition()`** is a **wide transformation** used to **increase or rearrange the number of partitions** of a DataFrame or RDD by **reshuffling** the data across the cluster.

### What happens during `repartition()`?

* **Full shuffle** of the data occurs across all executors.
* Spark reassigns data to a new set of partitions.
* Each record may move to a different node, increasing **network I/O**.

```python
# Syntax
df_repartitioned = df.repartition(8)  # Creates 8 partitions
```

---

## 🎯 When to Use `repartition()`?

| ✅ **Use When...**                                                        |
| ------------------------------------------------------------------------ |
| You want to **increase parallelism** before a wide transformation.       |
| Preparing data for **joins, aggregations, or shuffles**.                 |
| Writing large datasets to disk (e.g., S3, HDFS) for **parallel writes**. |
| You want to **distribute skewed data** more evenly.                      |

---

## ❌ When NOT to Use `repartition()`?

| ❌ **Avoid When...**                                                                    |
| -------------------------------------------------------------------------------------- |
| Data is small or fits in few partitions.                                               |
| You are **decreasing partitions** — use `coalesce()` instead.                          |
| You're performing `repartition()` right before an action that doesn’t benefit from it. |
| To avoid unnecessary **shuffle overhead**.                                             |

---

## ✅ Advantages of `repartition()`

* 🚀 **Improves parallelism** and throughput.
* ⚖️ Helps **balance load** across executors.
* 📦 Useful before **saving data** to distributed storage.
* 🧮 Helps with **shuffle-heavy operations** (e.g., `groupBy`, `join`).

---

## ❌ Disadvantages of `repartition()`

* 🔀 **Causes full shuffle**, which is expensive.
* 🕓 Increases **execution time** if used unnecessarily.
* 💾 Requires **network and disk I/O**, consuming more resources.

---

## 🧪 PySpark Example – Before vs After Repartition

### Dataset: Large file with transaction logs by region.

### ❌ Without Repartition

```python
from pyspark.sql import SparkSession
import time

spark = SparkSession.builder.appName("RepartitionExample").getOrCreate()

df = spark.read.csv("transactions.csv", header=True, inferSchema=True)

# Check number of partitions
print("Initial Partitions:", df.rdd.getNumPartitions())

# Grouping without repartition
start = time.time()
df.groupBy("region").count().show()
end = time.time()
print("Time without repartition:", end - start)
```

---

### ✅ With Repartition

```python
# Repartition by 'region' column for even distribution
df_repart = df.repartition("region")
print("Repartitioned Partitions:", df_repart.rdd.getNumPartitions())

# Perform groupBy after repartition
start = time.time()
df_repart.groupBy("region").count().show()
end = time.time()
print("Time with repartition:", end - start)
```

---

## 📈 Performance Comparison

| Metric            | Without Repartition | With Repartition |
| ----------------- | ------------------- | ---------------- |
| Shuffle Skew      | High                | Low              |
| Execution Time    | \~25 sec            | **\~12 sec**     |
| Load Balancing    | ❌ Poor              | ✅ Balanced       |
| Task Distribution | Imbalanced          | Optimized        |

---

## 🔁 Bonus: Compare With `coalesce()`

Use `coalesce(n)` to **reduce** the number of partitions **without shuffle** (used during saving/writing).

```python
df.coalesce(1).write.csv("output_folder")  # Write to single file
```

---

## ✅ Summary

| Feature        | `repartition()`       | `coalesce()`                 |
| -------------- | --------------------- | ---------------------------- |
| Shuffle        | ✅ Yes                 | ❌ No (narrow transformation) |
| Use Case       | Increase partitions   | Reduce partitions            |
| Speed          | Slower (shuffle cost) | Faster (no shuffle)          |
| Partition Size | More balanced         | Can be uneven                |
