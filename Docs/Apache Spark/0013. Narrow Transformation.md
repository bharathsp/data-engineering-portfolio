## 🔹 What is a **Narrow Transformation** in Spark?

A **Narrow Transformation** in Spark is a transformation where **each input partition contributes data to only one output partition**. There is **no data movement between partitions across nodes**, meaning **no shuffle happens**.

> ✅ Narrow transformations are **fast**, **memory-efficient**, and **easily pipelined**.

---

## 🔄 What Happens During a Narrow Transformation?

* Spark **records** the transformation (due to lazy evaluation).
* No **shuffling or network I/O** is triggered.
* When an **action** is executed, the transformation is applied **within the same partition**.
* It allows **pipelined execution**, improving performance.

---

## ✅ Common **Narrow Transformation** Functions

| Function       | Description                                             |
| -------------- | ------------------------------------------------------- |
| `map()`        | Applies a function to each record                       |
| `filter()`     | Filters rows based on a condition                       |
| `flatMap()`    | Similar to `map`, but allows multiple outputs per input |
| `union()`      | Combines two datasets                                   |
| `select()`     | Selects specific columns (for DataFrames)               |
| `withColumn()` | Adds or modifies a column                               |
| `sample()`     | Randomly samples data                                   |
| `limit()`      | Returns limited rows (for local actions)                |

---

## 🔧 PySpark Code Example – Narrow Transformation

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("NarrowTransformationExample").getOrCreate()

# Read CSV
df = spark.read.csv("data.csv", header=True, inferSchema=True)

# Narrow transformation: select columns
df_selected = df.select("name", "age")

# Narrow transformation: filter rows
df_filtered = df_selected.filter(df_selected["age"] > 30)

# Narrow transformation: add new column
df_final = df_filtered.withColumn("senior", df_filtered["age"] > 60)

# Action: triggers the transformations
df_final.show()
```

---

### 🧠 Internal Behavior (Execution Flow)

```text
[Partition1] -> filter -> withColumn -> stays in Partition1
[Partition2] -> filter -> withColumn -> stays in Partition2
... (no shuffle!)
```

---

## ✅ Advantages of Narrow Transformations

* 🚀 **High performance** due to no shuffle.
* 💡 **Efficient resource usage** (CPU & memory).
* 🧵 **Pipeline-able**: Multiple narrow ops can be executed together.
* 🌐 **No network dependency**.

---

## ❌ Limitations

* Limited to transformations that do not require data **from other partitions**.
* Can’t be used for **joins**, **grouping**, or **aggregations** (those are wide).

---

## 📌 Summary

| Feature              | Narrow Transformation                       |
| -------------------- | ------------------------------------------- |
| Partition Dependency | 1-to-1 (same partition)                     |
| Network Shuffle      | ❌ No                                        |
| Performance          | ✅ High                                      |
| Examples             | `map`, `filter`, `select`, `withColumn`     |
| Best Use Case        | Filtering, column selection, simple mapping |
