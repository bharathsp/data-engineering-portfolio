### ‚úÖ What are Kafka Consumers?

A **Kafka Consumer** is an application that **reads data** from Kafka **topics**.
Consumers **subscribe** to one or more topics and **fetch messages** from one or more **partitions** in real time.

Kafka consumers are:

* **Pull-based** (they request data)
* Track **offsets** (to know where they left off)
* Can be grouped into **consumer groups** for **scaling and load balancing**

---

### üì¶ Real-Life Example of Kafka Consumers

**Scenario: E-Commerce Website**

* **Producer**: Order Service sends order details to Kafka topic `order-events`.
* **Consumers**:

  * `BillingServiceConsumer` consumes messages to generate invoices.
  * `InventoryServiceConsumer` consumes the same messages to update stock.
  * `NotificationServiceConsumer` consumes the topic to send confirmation emails.

Each of these consumers **subscribes to the same topic**, but they can operate in **different consumer groups**.

---

### üß† Key Concepts

| Concept                  | Description                                                          |
| ------------------------ | -------------------------------------------------------------------- |
| **Offset**               | Pointer to the last message read in a partition                      |
| **Consumer Group**       | A group of consumers that share the load of consuming from a topic   |
| **Partition Assignment** | Kafka ensures each partition is read by only one consumer in a group |
| **Rebalancing**          | Happens when a consumer joins or leaves a group                      |

---

### üßë‚Äçüíª Kafka Consumer Code (Python)

Let‚Äôs create a Kafka consumer that listens to the `order-events` topic using `confluent-kafka`.

#### üìå Step 1: Install library

```bash
pip install confluent-kafka
```

#### üìå Step 2: Python Kafka Consumer Example

```python
from confluent_kafka import Consumer

# Kafka consumer configuration
conf = {
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'order-processing-group',
    'auto.offset.reset': 'earliest'  # read from beginning if no offset is stored
}

# Create consumer
consumer = Consumer(conf)

# Subscribe to topic
consumer.subscribe(['order-events'])

print("Waiting for messages...")

try:
    while True:
        msg = consumer.poll(1.0)  # Wait 1 sec for new messages
        if msg is None:
            continue
        if msg.error():
            print(f"Error: {msg.error()}")
        else:
            print(f"Received message: {msg.value().decode('utf-8')} from partition {msg.partition()}")
except KeyboardInterrupt:
    pass
finally:
    consumer.close()
```

---

### üßæ Output

```
Received message: {"order_id": "123", "product": "Laptop"} from partition 0
Received message: {"order_id": "124", "product": "Phone"} from partition 1
```

---

### üõ†Ô∏è Kafka Consumer Settings

| Setting              | Purpose                                                   |
| -------------------- | --------------------------------------------------------- |
| `group.id`           | Logical name of the consumer group                        |
| `auto.offset.reset`  | What to do if no offset is found (`earliest` or `latest`) |
| `enable.auto.commit` | Automatically commit offsets (default is True)            |

You can also **manually commit offsets** for more control:

```python
consumer.commit(asynchronous=False)
```

---

### ü§ù Consumer Group Parallelism

If you have:

* A topic with 3 partitions
* 3 consumers in one group

‚û°Ô∏è Kafka assigns 1 partition to each consumer, allowing parallel processing.
