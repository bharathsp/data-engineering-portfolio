## üìù Databricks Fundamentals ‚Äì Practice MCQ Test

### 1. What is the core purpose of Databricks?

A. Web application hosting
B. Unified analytics platform for data engineering, data science, and machine learning
C. File storage service
D. Cloud networking service

---

### 2. Databricks is built on top of which open-source framework?

A. Hadoop
B. Apache Spark
C. Apache Flink
D. Kafka

---

### 3. What is the Databricks Lakehouse?

A. A tool only for machine learning
B. A combination of data warehouse and data lake features
C. A type of cluster
D. A visualization library

---

### 4. Which of the following is NOT a Databricks cluster type?

A. All-purpose cluster
B. Job cluster
C. Pool cluster
D. Storage cluster

---

### 5. What is a Databricks notebook primarily used for?

A. Writing SQL only
B. Developing code, running queries, and visualizing results interactively
C. Only storing datasets
D. Only scheduling jobs

---

### 6. In Databricks, a ‚ÄúWorkspace‚Äù is best described as:

A. A storage volume for raw data
B. A collaborative environment for notebooks, libraries, and experiments
C. A compute engine for ML models
D. A job scheduling dashboard only

---

### 7. Delta Lake provides which main feature?

A. Streaming-only data pipelines
B. ACID transactions on data lakes
C. Serverless compute
D. Data visualization

---

### 8. Which of these languages is NOT supported in Databricks notebooks?

A. Python
B. SQL
C. Scala
D. PHP

---

### 9. Databricks ‚Äúpools‚Äù are used to:

A. Store datasets efficiently
B. Reduce cluster startup times by pre-warming instances
C. Increase SQL query cache performance
D. Deploy dashboards faster

---

### 10. In Databricks, MLflow is used for:

A. Workflow scheduling
B. Machine learning experiment tracking and model management
C. Streaming data ingestion
D. Security and governance

---

### 11. What is the default file format for Delta Lake tables?

A. Parquet with transaction log
B. ORC
C. Avro
D. CSV

---

### 12. Databricks SQL is designed for:

A. Writing machine learning code
B. Data governance
C. Querying structured data in the Lakehouse using SQL
D. Configuring clusters

---

### 13. What is a ‚Äújob‚Äù in Databricks?

A. A long-running cluster
B. A scheduled or triggered execution of a notebook, JAR, or Python script
C. A Spark SQL query
D. A data governance policy

---

### 14. Unity Catalog in Databricks helps with:

A. Data governance, access control, and lineage across the Lakehouse
B. Dashboard creation
C. Streaming ingestion
D. Visualization only

---

### 15. What does ‚ÄúPhoton‚Äù in Databricks refer to?

A. A hardware accelerator for ML
B. A vectorized query engine for fast execution of SQL and DataFrame operations
C. A data ingestion framework
D. A machine learning library

---

‚úÖ **Answer Key (self-check):**
1-B, 2-B, 3-B, 4-D, 5-B, 6-B, 7-B, 8-D, 9-B, 10-B, 11-A, 12-C, 13-B, 14-A, 15-B
