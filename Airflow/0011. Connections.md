### üîê What are **Connections** in Apache Airflow?

**Connections** in Airflow are **stored credentials and configuration** used to connect to external systems like databases, cloud services, APIs, or message queues.

---

### üß† **Simple Definition:**

> A **Connection** is a reusable config object in Airflow that contains all the details (host, port, login, password, etc.) needed to **connect to an external system**.

You reference these connections in **Hooks** and **Operators** using a `conn_id`.

---

### üì¶ **Example:**

You can define a connection in Airflow with:

* **conn\_id**: `my_postgres_conn`
* **Type**: `Postgres`
* **Host**: `localhost`
* **Schema**: `my_database`
* **Login**: `username`
* **Password**: `password`
* **Port**: `5432`

Then in your DAG:

```python
hook = PostgresHook(postgres_conn_id='my_postgres_conn')
```

Airflow will automatically **look up** this connection and use the stored credentials.

---

### üîß **Ways to Set Up Connections:**

#### 1. **Airflow Web UI**

* Go to: **Admin ‚Üí Connections**
* Click ‚Äú+‚Äù to add a new connection
* Fill out fields like `conn_id`, `conn_type`, `host`, `schema`, `login`, `password`, etc.

#### 2. **Environment Variables**

You can define a connection as an environment variable:

```bash
export AIRFLOW_CONN_MY_POSTGRES_CONN='postgresql://username:password@host:5432/dbname'
```

Note: The prefix must be `AIRFLOW_CONN_` and the value is a **URI-formatted string**.

#### 3. **airflow CLI**

```bash
airflow connections add 'my_postgres_conn' \
    --conn-uri 'postgresql://username:password@localhost:5432/my_database'
```

---

### üìö **Supported Connection Types:**

Airflow comes with built-in support for many systems:

| Type                    | System                       |
| ----------------------- | ---------------------------- |
| `postgres`              | PostgreSQL                   |
| `mysql`                 | MySQL                        |
| `http`                  | REST APIs                    |
| `aws`                   | AWS (e.g., S3, Redshift)     |
| `google_cloud_platform` | GCP services (BigQuery, GCS) |
| `sqlite`                | SQLite (for dev/test)        |
| `ftp`, `sftp`           | File transfer protocols      |
| `ssh`                   | Remote servers               |
| `jdbc`, `odbc`          | Java/ODBC connections        |

---

### üîÑ **How Connections Fit in Airflow Workflow:**

```
[DAG]
   ‚Üì
[Operator] ‚Üí uses ‚Üí
   ‚Üì
[Hook] ‚Üí gets creds from ‚Üí
   ‚Üì
[Connection] (defined via UI, ENV, or CLI)
```
