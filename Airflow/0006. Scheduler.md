## Scheduler

In **Apache Airflow**, the **Scheduler** is a **core component** responsible for:

> 🔄 **Monitoring DAGs and scheduling their tasks to run at the right time**.

---

### 🧠 **What the Scheduler Does:**

1. **Reads DAGs** from the DAG folder.
2. **Evaluates** the `schedule_interval` of each DAG.
3. **Creates DAG Runs** (instances of the DAG for a specific execution date).
4. **Schedules TaskInstances** that are ready to run.
5. Puts those tasks into a **queue** for execution by the **Executor**.

---

### 🕒 **Example:**

If you have a DAG with:

```python
schedule_interval='@daily'
start_date=datetime(2025, 7, 1)
```

The **Scheduler** will:

* Create a **DAG Run** for each day from `2025-07-01` onward (depending on `catchup=True/False`)
* Determine which tasks are ready to run based on dependencies and past status
* Send those tasks to the executor to be run

---

### 🔧 **Scheduler vs Executor:**

| Component     | Role                                         |
| ------------- | -------------------------------------------- |
| **Scheduler** | Decides *what to run* and *when to run*      |
| **Executor**  | Actually *executes* the task (runs the code) |

---

### 🔄 **How It Works in Real-Time:**

1. **Reads DAGs** every few seconds.
2. **Schedules DAG Runs** by evaluating if the current time matches the `schedule_interval`.
3. **Schedules Tasks** if their dependencies are met.
4. Hands them off to the **Executor** (e.g., LocalExecutor, CeleryExecutor, KubernetesExecutor).

---

### 📍 **Common Settings:**

In `airflow.cfg`:

* `scheduler_heartbeat_sec`: How frequently the scheduler checks for new DAGs.
* `min_file_process_interval`: Minimum wait time before processing the same DAG file again.

---

### 🧭 **Monitoring the Scheduler:**

* You can see its logs in:

  ```bash
  logs/scheduler/
  ```
* If it’s running correctly, the **Airflow UI** will show DAGs being triggered as expected.

---
