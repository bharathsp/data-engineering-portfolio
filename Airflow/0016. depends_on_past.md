### 🔁 `depends_on_past` in Apache Airflow

The **`depends_on_past`** parameter in Airflow is used to control whether a task should **wait for its own previous run to succeed** before running again.

---

### 🧠 **Simple Definition:**

> If `depends_on_past=True`, a task will **not run** for the current DAG run unless its **previous run was successful**.

---

### 📅 **Use Case Example:**

Suppose your DAG runs **daily**, and you have a task `load_to_db`:

```python
PythonOperator(
    task_id='load_to_db',
    python_callable=load_data,
    depends_on_past=True
)
```

* ✅ On **July 10**, the task runs successfully.
* 🟥 On **July 11**, it fails.
* 🔁 On **July 12**, it **will not run** because **July 11 failed**.

---

### 🧩 **Why Use `depends_on_past`?**

| Scenario                                           | Benefit                                           |
| -------------------------------------------------- | ------------------------------------------------- |
| **Data pipelines** that must process days in order | Ensures previous data is complete                 |
| **Incremental loading**                            | Prevents loading Day 3 before Day 2 is successful |
| **Avoids data duplication**                        | Won't reprocess unless previous batch was good    |

---

### 🔄 **Default Behavior:**

| Parameter         | Default |
| ----------------- | ------- |
| `depends_on_past` | `False` |

So by default, tasks do **not** wait on their own previous runs.

---

### 🔐 **Combined with Other Parameters:**

You can use it alongside:

```python
PythonOperator(
    task_id='transform_data',
    depends_on_past=True,
    retries=2,
    retry_delay=timedelta(minutes=5)
)
```

---

### ⚠️ Things to Note:

* `depends_on_past` only checks **the same task** in **previous DAG run**.
* If you **clear** a failed task in the UI and rerun it, the next one **can proceed**.
