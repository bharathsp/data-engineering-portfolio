# âš™ï¸ **Trino Configuration Tuning**

Trino has three main configuration files on the **coordinator** and **workers**:

1. `config.properties` â†’ General Trino configs (per node).
2. `jvm.config` â†’ JVM-level tuning.
3. `catalog/*.properties` â†’ Connector configs (Hive, Iceberg, MySQL, etc.).

---

## ğŸ”¹ 1. Coordinator Config Tuning (`config.properties`)

These impact query scheduling, memory, and cluster management.

### Key Parameters:

* `query.max-memory` â†’ Total memory a query can use cluster-wide.
* `query.max-memory-per-node` â†’ Memory per query per worker.
* `query.max-total-memory-per-node` â†’ Hard cap on per-node query memory (including system overhead).
* `query.queue-config-file` â†’ Controls query queues, priorities.
* `query.max-execution-time` â†’ Timeout for long queries.
* `query.low-memory-killer.policy=total-reservation` â†’ Kills largest queries if memory runs out (default).

ğŸ‘‰ **Tuning tip**:

* Set `query.max-memory` to \~50â€“60% of cluster memory.
* Balance `query.max-memory-per-node` vs. `query.max-total-memory-per-node` to avoid a single query hogging a node.

---

## ğŸ”¹ 2. Worker Config Tuning (`config.properties`)

Workers handle most of the heavy lifting.

* `task.concurrency` â†’ Number of concurrent splits (default 16).

  * Higher = better parallelism, but increases memory pressure.
* `task.max-worker-threads` â†’ Max worker threads. Default = cores.
* `sink.max-buffer-size` â†’ Buffer for output before flushing to disk (default 32MB).
* `exchange.client-threads` â†’ Threads for data exchange between workers.

ğŸ‘‰ **Tuning tip**:

* Start with `task.concurrency = 16`, increase to 32 if queries underutilize CPUs.
* Keep `task.max-worker-threads` = #cores.

---

## ğŸ”¹ 3. JVM Tuning (`jvm.config`)

Trino is **memory intensive**, so JVM configs are critical.

* `-Xmx` â†’ Max heap size. (Set to \~80% of node memory).
* `-XX:+UseG1GC` â†’ Garbage collector (default in Trino).
* `-XX:+UseGCOverheadLimit` â†’ Prevents excessive GC.
* `-XX:+ExitOnOutOfMemoryError` â†’ Restart on OOM.

ğŸ‘‰ **Tuning tip**:

* Use **G1GC** (default).
* Avoid too small heaps â†’ will cause frequent GC pauses.
* Example:

  ```bash
  -Xmx64G
  -XX:+UseG1GC
  -XX:+ExitOnOutOfMemoryError
  ```

---

## ğŸ”¹ 4. Connector-Level Tuning (`catalog/*.properties`)

### Hive/Iceberg:

* `hive.max-split-size` â†’ Default 64MB. Increase to 256MBâ€“512MB to reduce number of splits.
* `hive.max-outstanding-splits` â†’ Pending splits per node (default 1000). Increase for large datasets.
* `hive.parallel-partitioned-bucketed-inserts` â†’ Enables parallel writes.

### JDBC (MySQL, Postgres):

* `connection-pool-size` â†’ Increase if running many parallel queries.
* `metadata-cache-ttl` â†’ Cache metadata to reduce DB hits.

---

## ğŸ”¹ 5. Query Queues (Optional but Important)

Define queues to prevent large queries from starving smaller ones. Example `resource-groups.json`:

```json
{
  "rootGroups": [
    {
      "name": "global",
      "softMemoryLimit": "80%",
      "hardConcurrencyLimit": 100,
      "subGroups": [
        {
          "name": "etl",
          "softMemoryLimit": "60%",
          "hardConcurrencyLimit": 20,
          "schedulingPolicy": "fair"
        },
        {
          "name": "adhoc",
          "softMemoryLimit": "20%",
          "hardConcurrencyLimit": 10,
          "schedulingPolicy": "fair"
        }
      ]
    }
  ]
}
```

ğŸ‘‰ Separates **ETL workloads** from **ad-hoc queries**.

---

## ğŸ”¹ 6. Other Important Tuning Areas

* **Spill to Disk**: Enable if queries exceed memory.

  ```
  spill-enabled=true
  spiller-spill-path=/mnt/disks/trino_spill
  spiller-max-used-space-threshold=0.9
  ```
* **Fault Tolerance** (for retries):

  ```
  retry-policy=query
  ```

---

# âœ… Best Practices for Trino Tuning

1. **Memory-aware tuning** â†’ Balance `query.max-memory` and heap size.
2. **Bigger splits** for large datasets (reduce overhead).
3. **Use ORC/Parquet** instead of row-based formats (better I/O).
4. **Enable Spill-to-Disk** if memory is a bottleneck.
5. **Set up query queues** to isolate ETL and BI workloads.
6. **Monitor with Prometheus/Grafana** to see real bottlenecks.
