# Question 1

---

There is data in S3 and some data in SQL <br> 
S3->Orders data <br>
SQL -> Product data <br>
Use trino to combine the above data <br>

---

## ðŸ”¹ Step 1. Configure Trino Connectors

Trino connects to both **S3** (via Hive or Iceberg/Delta/Lakehouse connector) and **SQL** (e.g., MySQL, Postgres, SQL Server) by defining catalogs in the Trino `etc/catalog` directory.

### Example: S3 (Orders data via Hive catalog)

Create file: `etc/catalog/hive.properties`

```ini
connector.name=hive
hive.metastore.uri=thrift://<metastore-host>:9083
hive.s3.aws-access-key=YOUR_AWS_KEY
hive.s3.aws-secret-key=YOUR_AWS_SECRET
hive.s3.region=us-east-1
```

This lets you query tables like `hive.default.orders` (assuming Orders data is in S3 as Parquet/ORC/CSV).

---

### Example: SQL (Products data via MySQL)

Create file: `etc/catalog/mysql.properties`

```ini
connector.name=mysql
connection-url=jdbc:mysql://<mysql-host>:3306/productsdb
connection-user=trino_user
connection-password=your_password
```

This lets you query tables like `mysql.productsdb.products`.

---

## ðŸ”¹ Step 2. Example Tables

* **Orders (S3 via Hive)**

  ```sql
  CREATE TABLE hive.default.orders (
      order_id BIGINT,
      product_id BIGINT,
      customer_id BIGINT,
      quantity INT,
      order_date DATE
  )
  WITH (
      format = 'PARQUET',
      external_location = 's3a://your-bucket/orders/'
  );
  ```

* **Products (MySQL)**

  ```sql
  CREATE TABLE mysql.productsdb.products (
      product_id BIGINT,
      product_name VARCHAR,
      price DECIMAL(10,2),
      category VARCHAR
  );
  ```

---

## ðŸ”¹ Step 3. Query to Combine Data

Now you can **join across catalogs** in Trino:

```sql
SELECT 
    o.order_id,
    o.customer_id,
    o.order_date,
    p.product_name,
    p.category,
    o.quantity,
    (o.quantity * p.price) AS total_value
FROM hive.default.orders o
JOIN mysql.productsdb.products p
    ON o.product_id = p.product_id
WHERE o.order_date >= DATE '2025-01-01'
ORDER BY o.order_date DESC;
```

âœ… This query scans **Orders from S3** and **Products from SQL** â†’ joins them inside Trino without ETL.

---

## ðŸ”¹ Step 4. Optimization Tips

* Use **partitioning in S3** (e.g., partition Orders by `year`, `month`) so queries prune data:

  ```sql
  SELECT * FROM hive.default.orders WHERE order_date >= DATE '2025-09-01';
  ```

  â†’ Only reads September 2025 partitions.

* If the SQL table (Products) is small, use **broadcast join**:

  ```sql
  SET SESSION join_distribution_type = 'BROADCAST';
  ```

* For frequent queries, consider **materializing the join into a new table** in Iceberg/Delta on S3.

---

ðŸ‘‰ This way, Trino acts as a **federated query engine** combining your **data lake (S3)** and **database (SQL)** in one SQL query.
