### SQL / PySpark â€“ Employees in Departments Not Listed in Dept Table

---

### ðŸ§¾ **Emp Dataset**

| emp\_id | name     | superior\_emp\_id | year\_joined | emp\_dept\_id | gender | salary |
| ------- | -------- | ----------------- | ------------ | ------------- | ------ | ------ |
| 1       | Smith    | -1                | 2018         | 10            | M      | 3000   |
| 2       | Rose     | 1                 | 2010         | 20            | M      | 4000   |
| 3       | Williams | 1                 | 2010         | 10            | M      | 1000   |
| 4       | Jones    | 2                 | 2005         | 10            | F      | 2000   |
| 5       | Brown    | 2                 | 2010         | 40            |        | -1     |
| 6       | Brown    | 2                 | 2010         | 50            |        | -1     |

---

### ðŸ§¾ **Dept Dataset**

| dept\_name | dept\_id |
| ---------- | -------- |
| Finance    | 10       |
| Marketing  | 20       |
| Sales      | 30       |
| IT         | 40       |

---

### ðŸŽ¯ **Task:**

Find employees **whose department ID (`emp_dept_id`) does not exist** in the `Dept` table.

---

### âœ… **SQL Solution:**

```sql
SELECT *
FROM Emp e
LEFT JOIN Dept d
  ON e.emp_dept_id = d.dept_id
WHERE d.dept_id IS NULL;
```

---

### âœ… **PySpark Equivalent:**

```python
# Join Emp and Dept DataFrames
result_df = emp_df.join(dept_df, emp_df.emp_dept_id == dept_df.dept_id, how='left')

# Filter where dept info is missing
invalid_dept_df = result_df.filter(dept_df.dept_id.isNull()).select(emp_df.columns)

invalid_dept_df.show()
```

---

### ðŸ“¤ **Expected Output:**

| emp\_id | name  | superior\_emp\_id | year\_joined | emp\_dept\_id | gender | salary |
| ------- | ----- | ----------------- | ------------ | ------------- | ------ | ------ |
| 6       | Brown | 2                 | 2010         | 50            |        | -1     |
