### üì° **Sensors in Apache Airflow**

**Sensors** are special types of Airflow operators that **wait for a certain condition to be true** before allowing the workflow to proceed.

---

### üß† **Simple Definition:**

> A **Sensor** is a task that **pauses** the DAG‚Äôs execution **until something external happens**, such as:
>
> * A file landing in S3
> * A table appearing in a database
> * A certain time passing

---

### üîß **Common Use Cases:**

| Sensor Type          | What It Waits For                          |
| -------------------- | ------------------------------------------ |
| `S3KeySensor`        | A file appearing in an S3 bucket           |
| `FileSensor`         | A file appearing in a local or shared path |
| `ExternalTaskSensor` | A task in another DAG to complete          |
| `TimeDeltaSensor`    | A specific time to pass                    |
| `HttpSensor`         | An HTTP endpoint to return a success code  |
| `SqlSensor`          | A row to appear in a SQL table             |

---

### üîå **Basic Syntax Example (FileSensor):**

```python
from airflow import DAG
from airflow.sensors.filesystem import FileSensor
from datetime import datetime, timedelta

with DAG(
    dag_id="file_sensor_example",
    start_date=datetime(2025, 7, 1),
    schedule_interval="@daily",
    catchup=False
) as dag:

    wait_for_file = FileSensor(
        task_id="wait_for_file",
        filepath="/tmp/input.csv",
        poke_interval=30,      # Check every 30 seconds
        timeout=600            # Fail if not found within 10 minutes
    )
```

---

### ‚öôÔ∏è **Important Parameters:**

| Parameter       | Description                                                               |
| --------------- | ------------------------------------------------------------------------- |
| `poke_interval` | How often to check the condition (in seconds)                             |
| `timeout`       | Max time to wait before failing                                           |
| `mode`          | `poke` (default) or `reschedule`                                          |
| `soft_fail`     | If `True`, mark task as `skipped` instead of `failed` when timeout occurs |

---

### üîÅ **Sensor Modes:**

#### 1. üß† `poke` mode (default):

* Sensor **runs continuously**, checking the condition.
* Consumes a **worker slot** the entire time.
* Suitable for **quick, short waits**.

#### 2. üí§ `reschedule` mode:

* Sensor checks, then **releases the worker** and retries later.
* More efficient for **long waits** (e.g., files that arrive once a day).

```python
FileSensor(
    task_id='wait_for_file',
    filepath='/tmp/data.csv',
    mode='reschedule',
    poke_interval=300
)
```

---

### üß† **Best Practices:**

| Tip                                             | Why                                 |
| ----------------------------------------------- | ----------------------------------- |
| Use `reschedule` mode for long waits            | Saves resources                     |
| Set sensible `timeout` and `poke_interval`      | Avoid endless hangs                 |
| Avoid chaining multiple sensors                 | Can delay downstream tasks too much |
| Consider **deferrable sensors** in Airflow 2.2+ | Fully async and resource efficient  |

---

### ‚úÖ **Example: ExternalTaskSensor**

Waits for another DAG's task to succeed:

```python
from airflow.sensors.external_task import ExternalTaskSensor

ExternalTaskSensor(
    task_id='wait_for_downstream',
    external_dag_id='downstream_dag',
    external_task_id='final_task',
    mode='reschedule',
    timeout=3600
)
```
