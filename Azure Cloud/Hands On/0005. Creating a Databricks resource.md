1️⃣ How to **create an Azure Databricks workspace**
2️⃣ What **resources are automatically created** behind the scenes
3️⃣ How to **launch and access the Databricks workspace**

---

# ☁️ 1️⃣ Create an Azure Databricks Workspace (Portal Method)

### **Step 1: Open Azure Portal**

Go to 👉 [https://portal.azure.com](https://portal.azure.com) and sign in.

---

### **Step 2: Create Resource**

* Click **+ Create a resource** → Search **Databricks** → Select **Azure Databricks**.
  <img width="550" height="384" alt="image" src="https://github.com/user-attachments/assets/46887aae-9523-4dcf-9f69-7ae7b2c87a8e" />

  <img width="501" height="449" alt="image" src="https://github.com/user-attachments/assets/bb7c1903-f060-451b-9617-598c24c679b6" />


* Click **Create**.
<img width="552" height="450" alt="image" src="https://github.com/user-attachments/assets/ea0354bf-ed55-49ec-8e7b-2ea8def11d68" />

---

### **Step 3: Fill in the Basics**

You’ll see several configuration options.

| Field              | Description                                                           |
| ------------------ | --------------------------------------------------------------------- |
| **Subscription**   | Choose your active Azure subscription                                 |
| **Resource group** | Create new or select an existing one                                  |
| **Workspace name** | Must be unique (e.g., `databricks-ws-dev`)                            |
| **Region**         | Choose same region as your data sources if possible (for performance) |
| **Pricing Tier**   | Choose one of: Standard, Premium, or Trial (14 days free)             |

💡 **Tip:**

* Choose **Premium** if you need **role-based access**, **Unity Catalog**, or **job clusters**.
* **Standard** is fine for basic data engineering & notebooks.

---

### **Step 4: Networking (Optional)**

You can either:

* **Deploy with managed VNet (default)** → Azure manages networking.
* **Deploy with your own VNet (VNet injection)** → You manage security and subnets.

For beginners, keep **Managed VNet** selected.

---

### **Step 5: Review + Create**

* Review your settings.
* Click **Create**.
* Deployment usually takes **5–10 minutes**.

---

# ⚙️ 2️⃣ Resources Automatically Created with Databricks Workspace

When you create an Azure Databricks workspace, Azure **automatically provisions multiple underlying resources** to support it.

Here’s what gets created (depending on deployment type):

| Resource                            | Description                                                                      | Naming Convention Example   |
| ----------------------------------- | -------------------------------------------------------------------------------- | --------------------------- |
| 🧱 **Databricks Workspace**         | The main managed resource visible in the portal                                  | `databricks-ws-dev`         |
| ☁️ **Managed Resource Group**       | Auto-created by Azure; contains Databricks-managed infrastructure                | `databricks-rg-<random-id>` |
| 💻 **Virtual Network (VNet)**       | For Databricks control plane & worker communication (if VNet injection not used) | `databricks-vnet`           |
| 🔄 **Network Interfaces / Subnets** | For clusters, driver, and worker nodes                                           | `databricks-nic-<id>`       |
| 💾 **Storage Account**              | Used for DBFS root storage (Databricks File System)                              | `dbstorage<random>`         |
| 🔑 **Managed Identity (MSI)**       | Used for secure access to storage and other Azure services                       | `databricks-msi-<id>`       |

> ⚠️ You **should not manually delete** resources in the managed resource group (`databricks-rg-*`).
> Doing so can **break the workspace**.

---

# 🚀 3️⃣ Launch and Use the Databricks Workspace

### **Step 1: Go to your Databricks workspace**

In the Azure Portal:

* Navigate to your resource → **Azure Databricks Workspace**.
* Click **Launch Workspace** button (top-right corner).

This opens the Databricks web UI in a new tab:

```
https://<region>.azuredatabricks.net
```

---

### **Step 2: Sign in**

It uses your Azure AD credentials — no separate login needed.

---

### **Step 3: Inside Databricks Workspace**

Once it opens, you’ll see:

| Section                       | Purpose                                                           |
| ----------------------------- | ----------------------------------------------------------------- |
| 🧑‍💻 **Workspace**           | Store and organize notebooks, jobs, libraries                     |
| ⚙️ **Compute (Clusters)**     | Create clusters (Spark runtime) to run notebooks                  |
| 📂 **Data**                   | Access to DBFS (Databricks File System) and external data sources |
| 🧩 **Jobs**                   | Schedule production jobs                                          |
| 🧠 **Model Serving / MLflow** | For ML model tracking and deployment (Premium tier)               |

---

# 💻 4️⃣ Quick Start — Launch a Cluster

To actually run Spark jobs:

1. In the left sidebar, click **Compute → + Create Cluster**
2. Give it a **name**
3. Choose **Runtime version** (e.g., *10.4 LTS (includes Apache Spark 3.2)*)
4. Select **Worker Type** and **Worker Count** (e.g., 2 workers)
5. Click **Create Cluster**

✅ Once it’s running (takes a few minutes), you can attach notebooks and start running PySpark, SQL, or ML code.

---

# 🧠 5️⃣ Summary — What Happens Behind the Scenes

| Step                   | What Happens                                                |
| ---------------------- | ----------------------------------------------------------- |
| 🏗️ Workspace creation | Azure provisions Databricks workspace and managed resources |
| ⚙️ Cluster creation    | Databricks spins up VMs inside the managed resource group   |
| 💾 Storage setup       | Databricks mounts DBFS using storage account                |
| 🔑 Authentication      | Integrated with Azure AD                                    |
| 🌐 Access              | Through `azuredatabricks.net` web UI                        |

---

# 🔍 6️⃣ (Optional) Create via Azure CLI

```bash
az databricks workspace create \
  --resource-group my-rg \
  --name my-databricks-ws \
  --location eastus \
  --sku premium
```

To launch via CLI:

```bash
az databricks workspace show --resource-group my-rg --name my-databricks-ws
```

Then open the `workspaceUrl` in your browser.

---

Would you like me to include a **diagram with icons** showing the **Databricks workspace architecture (control plane + data plane + managed resources)** for clearer understanding?
