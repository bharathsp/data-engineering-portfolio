1️⃣ How to **create an Azure Databricks workspace**<br>
2️⃣ What **resources are automatically created** behind the scenes<br>
3️⃣ How to **launch and access the Databricks workspace**<br>

---

# ☁️ 1️⃣ Create an Azure Databricks Workspace (Portal Method)

### **Step 1: Open Azure Portal**

Go to 👉 [https://portal.azure.com](https://portal.azure.com) and sign in.

---

### **Step 2: Create Resource**

* Click **+ Create a resource** → Search **Databricks** → Select **Azure Databricks**.
  <img width="550" height="384" alt="image" src="https://github.com/user-attachments/assets/46887aae-9523-4dcf-9f69-7ae7b2c87a8e" />

  <img width="501" height="449" alt="image" src="https://github.com/user-attachments/assets/bb7c1903-f060-451b-9617-598c24c679b6" />


* Click **Create**.
<img width="552" height="450" alt="image" src="https://github.com/user-attachments/assets/ea0354bf-ed55-49ec-8e7b-2ea8def11d68" />

---

### **Step 3: Fill in the Basics**

You’ll see several configuration options.

| Field              | Description                                                           |
| ------------------ | --------------------------------------------------------------------- |
| **Subscription**   | Choose your active Azure subscription                                 |
| **Resource group** | Create new or select an existing one                                  |
| **Workspace name** | Must be unique (e.g., `databricks-ws-dev`)                            |
| **Region**         | Choose same region as your data sources if possible (for performance) |
| **Pricing Tier**   | Choose one of: Standard, Premium, or Trial (14 days free)             |

<img width="517" height="942" alt="image" src="https://github.com/user-attachments/assets/79f020ba-d1a5-4821-b903-6a596b30d429" />

💡 **Tip:**

* Choose **Premium** if you need **role-based access**, **Unity Catalog**, or **job clusters**.
* **Standard** is fine for basic data engineering & notebooks.

---

### **Step 4: Networking (Optional)**

You can either:

* **Deploy with managed VNet (default)** → Azure manages networking.
* **Deploy with your own VNet (VNet injection)** → You manage security and subnets.

For beginners, keep **Managed VNet** selected.<br>
<img width="544" height="343" alt="image" src="https://github.com/user-attachments/assets/a74e6c85-8f4e-4a84-bb54-09cdcaaf8471" />

---

### **Step 5: Review + Create**

* Review your settings.
* Click **Create**.
* Deployment usually takes **5–10 minutes**.

<img width="505" height="931" alt="image" src="https://github.com/user-attachments/assets/aedb0991-ed87-45da-8f75-5e920881d4ba" />

<img width="578" height="608" alt="image" src="https://github.com/user-attachments/assets/68757187-5947-404a-9d73-17dfe7d18c8c" />

<img width="559" height="623" alt="image" src="https://github.com/user-attachments/assets/283fef12-f0d3-4a20-b9e7-a3943cc35b42" />

---

# ⚙️ 2️⃣ Resources Automatically Created with Databricks Workspace

When you create an Azure Databricks workspace, Azure **automatically provisions multiple underlying resources** to support it.

Here’s what gets created (depending on deployment type):

| Resource                            | Description                                                                      | Naming Convention Example   |
| ----------------------------------- | -------------------------------------------------------------------------------- | --------------------------- |
| 🧱 **Databricks Workspace**         | The main managed resource visible in the portal                                  | `databricks-ws-dev`         |
| ☁️ **Managed Resource Group**       | Auto-created by Azure; contains Databricks-managed infrastructure                | `databricks-rg-<random-id>` |
| 💻 **Virtual Network (VNet)**       | For Databricks control plane & worker communication (if VNet injection not used) | `databricks-vnet`           |
| 🔄 **Network Interfaces / Subnets** | For clusters, driver, and worker nodes                                           | `databricks-nic-<id>`       |
| 💾 **Storage Account**              | Used for DBFS root storage (Databricks File System)                              | `dbstorage<random>`         |
| 🔑 **Managed Identity (MSI)**       | Used for secure access to storage and other Azure services                       | `databricks-msi-<id>`       |

> ⚠️ You **should not manually delete** resources in the managed resource group (`databricks-rg-*`).
> Doing so can **break the workspace**.

<img width="519" height="687" alt="image" src="https://github.com/user-attachments/assets/0034e2ef-efce-425b-b00e-2f91817833ea" />

---

# 🚀 3️⃣ Launch and Use the Databricks Workspace

### **Step 1: Go to your Databricks workspace**

In the Azure Portal:

* Navigate to your resource → **Azure Databricks Workspace**.
* Click **Launch Workspace** button (top-right corner).

This opens the Databricks web UI in a new tab:

```
https://<region>.azuredatabricks.net
```

<img width="954" height="487" alt="image" src="https://github.com/user-attachments/assets/820bc3db-b02a-4edb-9ab0-c6c4af8ca883" />

---

### **Step 2: Sign in**

It uses your Azure AD credentials — no separate login needed.

---

### **Step 3: Inside Databricks Workspace**

Once it opens, you’ll see:

| Section                       | Purpose                                                           |
| ----------------------------- | ----------------------------------------------------------------- |
| 🧑‍💻 **Workspace**           | Store and organize notebooks, jobs, libraries                     |
| ⚙️ **Compute (Clusters)**     | Create clusters (Spark runtime) to run notebooks                  |
| 📂 **Data**                   | Access to DBFS (Databricks File System) and external data sources |
| 🧩 **Jobs**                   | Schedule production jobs                                          |
| 🧠 **Model Serving / MLflow** | For ML model tracking and deployment (Premium tier)               |

<img width="519" height="860" alt="image" src="https://github.com/user-attachments/assets/f01c18e4-ca66-41cc-9430-49aa4121c9eb" />

---

# 💻 4️⃣ Quick Start — Launch a Cluster

To actually run Spark jobs:

1. In the left sidebar, click **Compute → + Create Cluster**
   <img width="959" height="400" alt="image" src="https://github.com/user-attachments/assets/f6213c64-5d69-4314-88b7-e11bc460f059" />

2. Give it a **name**
3. Choose **Runtime version** (e.g., *10.4 LTS (includes Apache Spark 3.2)*)
4. Select **Worker Type** and **Worker Count** (e.g., 2 workers)
5. Click **Create Cluster**

<img width="1920" height="1976" alt="screencapture-adb-2501887048148376-16-azuredatabricks-net-compute-clusters-new-2025-10-08-14_43_24" src="https://github.com/user-attachments/assets/edd93527-50ef-4f38-ada6-734ed0bdbbf5" />

✅ Once it’s running (takes a few minutes), you can attach notebooks and start running PySpark, SQL, or ML code.

---

# 🧠 5️⃣ Summary — What Happens Behind the Scenes

| Step                   | What Happens                                                |
| ---------------------- | ----------------------------------------------------------- |
| 🏗️ Workspace creation | Azure provisions Databricks workspace and managed resources |
| ⚙️ Cluster creation    | Databricks spins up VMs inside the managed resource group   |
| 💾 Storage setup       | Databricks mounts DBFS using storage account                |
| 🔑 Authentication      | Integrated with Azure AD                                    |
| 🌐 Access              | Through `azuredatabricks.net` web UI                        |

---

# 🔍 6️⃣ (Optional) Create via Azure CLI

```bash
az databricks workspace create \
  --resource-group my-rg \
  --name my-databricks-ws \
  --location eastus \
  --sku premium
```

To launch via CLI:

```bash
az databricks workspace show --resource-group my-rg --name my-databricks-ws
```

Then open the `workspaceUrl` in your browser.
