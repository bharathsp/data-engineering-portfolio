# ğŸ¤– **Spark MLlib (Machine Learning Library)**

## ğŸ§© What is it?

* **MLlib** is Apache Sparkâ€™s **machine learning library**.
* Provides scalable implementations of **machine learning algorithms** and **utilities**.
* Runs **distributed** on large datasets, unlike scikit-learn which is **single-node**.

---

# âš¡ Capabilities of MLlib

### 1ï¸âƒ£ **Supervised Learning**

* ğŸ“ˆ **Regression**

  * `LinearRegression`
  * `DecisionTreeRegressor`
  * `RandomForestRegressor`
  * `GBTRegressor` (Gradient Boosted Trees)

* âœ… **Classification**

  * `LogisticRegression`
  * `NaiveBayes`
  * `DecisionTreeClassifier`
  * `RandomForestClassifier`
  * `GBTClassifier`
  * `LinearSVC` (Support Vector Machines)

---

### 2ï¸âƒ£ **Unsupervised Learning**

* ğŸ“Š **Clustering**

  * `KMeans`
  * `GaussianMixture`
  * `LDA` (Latent Dirichlet Allocation â€“ topic modeling)

* ğŸ” **Dimensionality Reduction**

  * `PCA` (Principal Component Analysis)
  * `SVD` (Singular Value Decomposition)

---

### 3ï¸âƒ£ **Recommendations**

* ğŸ¬ **Collaborative Filtering**

  * `ALS` (Alternating Least Squares) â†’ used for **recommendation systems** (like Netflix, Amazon).

---

### 4ï¸âƒ£ **Utilities**

* Feature extraction & transformation (e.g., `VectorAssembler`, `StringIndexer`, `OneHotEncoder`).
* Pipelines for building end-to-end ML workflows.
* Model evaluation metrics (`RegressionEvaluator`, `MulticlassClassificationEvaluator`, etc.).

---

# ğŸ“š Library for MLlib

All ML algorithms are in the **`pyspark.ml`** package.

```python
# Regression
from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor

# Classification
from pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier

# Clustering
from pyspark.ml.clustering import KMeans

# Dimensionality Reduction
from pyspark.ml.feature import PCA

# Recommendation
from pyspark.ml.recommendation import ALS
```

---

# ğŸ—ï¸ Example: Linear Regression

```python
from pyspark.sql import SparkSession
from pyspark.ml.regression import LinearRegression

spark = SparkSession.builder.appName("MLlibExample").getOrCreate()

# Sample training data
data = [(1, 2.0, 1.0), (2, 3.0, 2.0), (3, 4.0, 3.0)]
columns = ["label", "feature1", "feature2"]

df = spark.createDataFrame(data, columns)

# Assemble features into a vector
from pyspark.ml.feature import VectorAssembler
assembler = VectorAssembler(inputCols=["feature1", "feature2"], outputCol="features")
train_df = assembler.transform(df)

# Train model
lr = LinearRegression(featuresCol="features", labelCol="label")
model = lr.fit(train_df)

# Print coefficients
print("Coefficients:", model.coefficients)
print("Intercept:", model.intercept)
```

---

# ğŸ–¼ï¸ Analogy

Think of MLlib as a **gym ğŸ‹ï¸â€â™‚ï¸**:

* **Trainers** = Algorithms (regression, clustering, classification).
* **Workout tools** = Transformers & Feature Extractors.
* **Workout plan** = Pipelines.
* **Fitness test** = Evaluators.

---

# âœ… Summary

* **Spark MLlib** = Scalable ML library in Spark.
* Supports **regression, classification, clustering, dimensionality reduction, recommendations**.
* Use **`pyspark.ml`** package.
* Provides **pipelines, transformers, evaluators** for complete ML workflows.
