Certainly! Here's the fully rephrased question including both **input** and **expected outputs**:

---

### **Question:**

You are given a PySpark DataFrame with the following data:

#### **Input DataFrame (`df`)**

| Col1 | col2 |
| ---- | ---- |
| 1    | a    |
| 1    | a    |
| 1    | c    |
| 2    | d    |
| 2    | e    |
| 3    | g    |
| 3    | h    |

---

### **Tasks:**

1. **Group the data by `Col1` and return a list of distinct values from `col2`.**

   #### **Expected Output:**

   | Col1 | col2\_list |
   | ---- | ---------- |
   | 1    | \[a, c]    |
   | 2    | \[d, e]    |
   | 3    | \[g, h]    |

---

2. **Group the data by `Col1` and return a list of all values from `col2`, including duplicates.**

   #### **Expected Output:**

   | Col1 | col2\_list |
   | ---- | ---------- |
   | 1    | \[a, a, c] |
   | 2    | \[d, e]    |
   | 3    | \[g, h]    |

---

### ✅ First Output (distinct values grouped as list):

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import collect_set

# Sample data
data = [(1, 'a'), (1, 'a'), (1, 'c'), (2, 'd'), (2, 'e'), (3, 'g'), (3, 'h')]
df = spark.createDataFrame(data, ["Col1", "col2"])

# Group by Col1 and collect unique col2 values as list
result_distinct = df.groupBy("Col1").agg(collect_set("col2").alias("col2_list"))

result_distinct.show(truncate=False)
```

**Output:**

```
+-----+---------+
|Col1 |col2_list|
+-----+---------+
|1    |[a, c]   |
|2    |[d, e]   |
|3    |[g, h]   |
+-----+---------+
```

---

### ✅ Second Output (preserve duplicates grouped as list):

```python
from pyspark.sql.functions import collect_list

# Group by Col1 and collect all col2 values (including duplicates)
result_all = df.groupBy("Col1").agg(collect_list("col2").alias("col2_list"))

result_all.show(truncate=False)
```

**Output:**

```
+-----+------------+
|Col1 |col2_list   |
+-----+------------+
|1    |[a, a, c]   |
|2    |[d, e]      |
|3    |[g, h]      |
+-----+------------+
```
