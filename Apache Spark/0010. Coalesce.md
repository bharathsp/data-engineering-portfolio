## 🧩 What is `coalesce()` in Spark?

In Apache Spark, **`coalesce(n)`** is a **narrow transformation** used to **reduce the number of partitions** in a DataFrame or RDD **without triggering a full shuffle**.

* It tries to **minimize data movement** by collapsing existing partitions.
* Best suited for **decreasing** partitions, especially during **write operations**.

```python
# Syntax
df_coalesced = df.coalesce(4)
```

---

## 🔍 What Happens Internally During `coalesce()`?

* Spark **merges adjacent partitions**.
* Data **stays on the same executor** as much as possible.
* Unlike `repartition()`, it **avoids shuffling data across the cluster**.

---

## ✅ When to Use `coalesce()`?

| ✅ **Ideal Use Cases**                                                  |
| ---------------------------------------------------------------------- |
| Writing output files (e.g., to HDFS, S3) and you want **fewer files**. |
| Reducing number of partitions **after transformation-heavy steps**.    |
| Avoiding **shuffle overhead** of `repartition()` when shrinking data.  |
| Final step of an ETL pipeline to optimize storage.                     |

---

## ❌ When Not to Use `coalesce()`?

| ❌ **Avoid `coalesce()` When...**                                     |
| -------------------------------------------------------------------- |
| You need to **increase partitions** (use `repartition()` instead).   |
| The data is **heavily skewed** or needs full rebalance.              |
| You want **even-sized partitions** (coalesce can produce imbalance). |

---

## ✅ Advantages of `coalesce()`

* 🚀 Faster than `repartition()` since it **avoids shuffle**.
* 💾 Reduces **I/O and storage cost** when writing fewer output files.
* 🧠 Memory efficient.

---

## ❌ Disadvantages of `coalesce()`

* ⚠️ **Partition sizes may be uneven**, leading to **skewed task execution**.
* 📉 May lead to **under-utilization of executors** if not tuned.
* ❌ Only works for **reducing** partitions, not increasing.

---

## 🧪 PySpark Code Example – Before vs After Using `coalesce()`

### Dataset: Assume a DataFrame with 200 partitions.

### ❌ Without `coalesce()` (Default Output)

```python
from pyspark.sql import SparkSession
import time

spark = SparkSession.builder.appName("CoalesceExample").getOrCreate()

df = spark.read.csv("large_dataset.csv", header=True, inferSchema=True)
print("Initial partitions:", df.rdd.getNumPartitions())

start = time.time()
df.write.mode("overwrite").csv("output/default")  # Writes 200+ files
end = time.time()
print("Time without coalesce:", end - start)
```

---

### ✅ With `coalesce()` (Reduced Output Files)

```python
# Reduce number of partitions to 1 (single file output)
df_coalesced = df.coalesce(1)
print("Partitions after coalesce:", df_coalesced.rdd.getNumPartitions())

start = time.time()
df_coalesced.write.mode("overwrite").csv("output/coalesced")  # Writes 1 file
end = time.time()
print("Time with coalesce:", end - start)
```

---

## 📈 Performance Comparison

| Metric            | Without `coalesce()`         | With `coalesce(1)`                          |
| ----------------- | ---------------------------- | ------------------------------------------- |
| Output Files      | \~200 CSV files              | **1 file**                                  |
| Write Performance | Slower (more I/O)            | Faster (optimized writes)                   |
| Shuffle Involved  | Yes (if using `repartition`) | **No** (narrow op)                          |
| Partition Skew    | Balanced                     | May be uneven (acceptable for final output) |

---

## 🔁 `coalesce()` vs `repartition()`

| Feature           | `coalesce()`          | `repartition()`                   |
| ----------------- | --------------------- | --------------------------------- |
| Shuffle           | ❌ No                  | ✅ Yes                             |
| Used For          | Decreasing partitions | Increasing or changing partitions |
| Speed             | ✅ Faster              | ❌ Slower (due to shuffle)         |
| Partition Balance | May be uneven         | Balanced                          |
| Final Output Use  | ✅ Recommended         | ❌ Avoid unless necessary          |

---

## ✅ Summary

* Use `coalesce()` when you **want to reduce partitions** (especially before writing data).
* Avoid using it if you need to **increase or balance** partitions.
* Great for **improving performance and reducing output file counts** in production pipelines.
