### üîç **What is Pushdown Predicate in Spark?**

**Predicate Pushdown** is a Spark optimization technique where **filter operations are pushed down to the data source layer** (like Parquet, ORC, JDBC, etc.) instead of applying them after the full data is read into Spark.

---

### ‚úÖ **Why is Predicate Pushdown Important?**

It helps Spark **avoid reading unnecessary data** by applying filters **as early as possible**, directly at the source, which:

* Reduces **IO (input/output)** from disk or database.
* Minimizes **data transferred** over the network.
* Improves **overall performance**.

---

### üéØ **Example: Without vs With Predicate Pushdown**

#### **Scenario**: Reading a Parquet file of customers and filtering by country.

```python
# Read Parquet file
df = spark.read.parquet("s3://mybucket/customers")

# Filter customers from India
df_india = df.filter(df.country == "India")
```

‚û°Ô∏è **With predicate pushdown**: Spark **instructs the Parquet reader** to only load rows where `country = 'India'`.

‚û°Ô∏è **Without predicate pushdown**: Spark **reads all rows** from the Parquet file, and applies the filter in memory ‚Äî less efficient.

---

### üì¶ **Supported Data Sources for Pushdown**

| Data Source | Predicate Pushdown Supported? |
| ----------- | ----------------------------- |
| Parquet     | ‚úÖ Yes                         |
| ORC         | ‚úÖ Yes                         |
| JDBC        | ‚úÖ Yes (translated to SQL)     |
| Delta Lake  | ‚úÖ Yes                         |
| CSV/JSON    | ‚ùå No                          |

---

### üîß **How to Check Predicate Pushdown in Spark?**

Use **`explain()`** to view the physical plan and confirm pushdown.

```python
df_india.explain(True)
```

Look for entries like:

```
PushedFilters: [EqualTo(country,India)]
```

---

### üõë **When Pushdown May Not Happen**

* Using **UDFs** in the filter.
* Complex expressions or unsupported functions.
* Reading from formats like CSV or JSON.

---

### ‚öôÔ∏è **JDBC Example with Pushdown**

```python
df = spark.read \
    .format("jdbc") \
    .option("url", "jdbc:mysql://host/db") \
    .option("dbtable", "customers") \
    .option("user", "user") \
    .option("password", "pass") \
    .load()

df_filtered = df.filter("country = 'India'")
df_filtered.explain(True)
```

Check for SQL-like predicates being pushed to the query:
`PushedFilters: [EqualTo(country,India)]`

---

### üí° TL;DR

| Aspect        | Predicate Pushdown                                   |
| ------------- | ---------------------------------------------------- |
| What is it?   | Filtering data **at source**, not after loading      |
| Benefit       | Faster performance, reduced IO                       |
| When it works | On supported formats like Parquet, ORC, JDBC         |
| How to verify | Use `df.explain(True)` and check for `PushedFilters` |
| Limitation    | Doesn‚Äôt work with UDFs or some data formats          |
