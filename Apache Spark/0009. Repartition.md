## ğŸ”„ What is `repartition()` in Spark?

In Apache Spark, **`repartition()`** is a **wide transformation** used to **increase or rearrange the number of partitions** of a DataFrame or RDD by **reshuffling** the data across the cluster.

### What happens during `repartition()`?

* **Full shuffle** of the data occurs across all executors.
* Spark reassigns data to a new set of partitions.
* Each record may move to a different node, increasing **network I/O**.

```python
# Syntax
df_repartitioned = df.repartition(8)  # Creates 8 partitions
```

---

## ğŸ¯ When to Use `repartition()`?

| âœ… **Use When...**                                                        |
| ------------------------------------------------------------------------ |
| You want to **increase parallelism** before a wide transformation.       |
| Preparing data for **joins, aggregations, or shuffles**.                 |
| Writing large datasets to disk (e.g., S3, HDFS) for **parallel writes**. |
| You want to **distribute skewed data** more evenly.                      |

---

## âŒ When NOT to Use `repartition()`?

| âŒ **Avoid When...**                                                                    |
| -------------------------------------------------------------------------------------- |
| Data is small or fits in few partitions.                                               |
| You are **decreasing partitions** â€” use `coalesce()` instead.                          |
| You're performing `repartition()` right before an action that doesnâ€™t benefit from it. |
| To avoid unnecessary **shuffle overhead**.                                             |

---

## âœ… Advantages of `repartition()`

* ğŸš€ **Improves parallelism** and throughput.
* âš–ï¸ Helps **balance load** across executors.
* ğŸ“¦ Useful before **saving data** to distributed storage.
* ğŸ§® Helps with **shuffle-heavy operations** (e.g., `groupBy`, `join`).

---

## âŒ Disadvantages of `repartition()`

* ğŸ”€ **Causes full shuffle**, which is expensive.
* ğŸ•“ Increases **execution time** if used unnecessarily.
* ğŸ’¾ Requires **network and disk I/O**, consuming more resources.

---

## ğŸ§ª PySpark Example â€“ Before vs After Repartition

### Dataset: Large file with transaction logs by region.

### âŒ Without Repartition

```python
from pyspark.sql import SparkSession
import time

spark = SparkSession.builder.appName("RepartitionExample").getOrCreate()

df = spark.read.csv("transactions.csv", header=True, inferSchema=True)

# Check number of partitions
print("Initial Partitions:", df.rdd.getNumPartitions())

# Grouping without repartition
start = time.time()
df.groupBy("region").count().show()
end = time.time()
print("Time without repartition:", end - start)
```

---

### âœ… With Repartition

```python
# Repartition by 'region' column for even distribution
df_repart = df.repartition("region")
print("Repartitioned Partitions:", df_repart.rdd.getNumPartitions())

# Perform groupBy after repartition
start = time.time()
df_repart.groupBy("region").count().show()
end = time.time()
print("Time with repartition:", end - start)
```

---

## ğŸ“ˆ Performance Comparison

| Metric            | Without Repartition | With Repartition |
| ----------------- | ------------------- | ---------------- |
| Shuffle Skew      | High                | Low              |
| Execution Time    | \~25 sec            | **\~12 sec**     |
| Load Balancing    | âŒ Poor              | âœ… Balanced       |
| Task Distribution | Imbalanced          | Optimized        |

---

## ğŸ” Bonus: Compare With `coalesce()`

Use `coalesce(n)` to **reduce** the number of partitions **without shuffle** (used during saving/writing).

```python
df.coalesce(1).write.csv("output_folder")  # Write to single file
```

---

## âœ… Summary

| Feature        | `repartition()`       | `coalesce()`                 |
| -------------- | --------------------- | ---------------------------- |
| Shuffle        | âœ… Yes                 | âŒ No (narrow transformation) |
| Use Case       | Increase partitions   | Reduce partitions            |
| Speed          | Slower (shuffle cost) | Faster (no shuffle)          |
| Partition Size | More balanced         | Can be uneven                |
