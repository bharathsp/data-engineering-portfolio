# âš¡ **What is Structured Streaming?**

* **Structured Streaming** is a **stream processing engine** built on top of Spark SQL.
* Processes data streams as **unbounded tables** (infinite DataFrames).
* Provides a **declarative API (SQL/DataFrames)** instead of low-level DStreams.
* Handles **event-time**, **watermarking**, **exactly-once guarantees**.
* Itâ€™s the **successor to Spark Streaming** (RDD-based).

ğŸ‘‰ In short: itâ€™s **real-time DataFrames**.

---

# ğŸ—ï¸ How It Works

1. Incoming stream of data = treated as an **infinite table**.
2. Each new batch of data = **new rows appended**.
3. You write queries using **DataFrame API or SQL**.
4. Spark executes queries **incrementally** as new data arrives.

---

# ğŸ“Š Example: Structured Streaming Word Count

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("StructuredStreaming").getOrCreate()

# Read stream from socket
lines = spark.readStream.format("socket") \
    .option("host", "localhost") \
    .option("port", 9999) \
    .load()

# Split into words
from pyspark.sql.functions import explode, split
words = lines.select(explode(split(lines.value, " ")).alias("word"))

# Count words
word_counts = words.groupBy("word").count()

# Output to console
query = word_counts.writeStream \
    .outputMode("complete") \
    .format("console") \
    .start()

query.awaitTermination()
```

---

# â–¶ï¸ How to Run

1. Start a socket server:

   ```bash
   nc -lk 9999
   ```
2. Type messages (e.g., `hello structured streaming spark spark`).
3. Spark updates the **console output** with live word counts.

---

# ğŸ”„ Output Modes

* **Append** â†’ Only new rows are written.
* **Complete** â†’ Entire result table updated each time.
* **Update** â†’ Only updated rows are written.

---

# ğŸ“¡ Sources

Structured Streaming supports:

* **Socket (TCP)**
* **Kafka**
* **Files (CSV, JSON, Parquet)**
* **Rate generator (testing)**

---

# ğŸ› ï¸ Sinks (Where to Output)

* Console (debugging)
* Files (CSV, JSON, Parquet)
* Kafka
* Memory (for debugging SQL queries)

---

# ğŸ–¼ï¸ Real-Life Use Cases

* ğŸ“Š **Real-time dashboards** â†’ Monitoring web traffic/logs.
* ğŸ’³ **Fraud detection** â†’ Flagging suspicious credit card transactions.
* ğŸ“¦ **IoT streaming** â†’ Analyzing sensor/telemetry data.
* ğŸ“¡ **ETL pipelines** â†’ Incrementally ingesting & transforming data.
* ğŸ¦ **Social media analytics** â†’ Processing tweets or comments in real-time.

---

# ğŸ–¼ï¸ Analogy

Think of a **live spreadsheet ğŸ“Š**:

* New rows keep getting added (stream).
* Formulas (queries) are **always running**.
* You see updated results continuously.

---

# âœ… Summary

* **Structured Streaming** = real-time DataFrames (not micro-batches like old Spark Streaming).
* Built on **Spark SQL** â†’ easier, more powerful, supports event-time & exactly-once.
* Sources = Kafka, sockets, files; Sinks = console, Kafka, files.
* Best choice for **new streaming projects** in Spark.
