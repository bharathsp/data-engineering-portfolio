# 🔑 **Pair RDDs (Key-Value RDDs)**

## 🧩 What is a Pair RDD?

* A **Pair RDD** is just an RDD where each element is a **key-value pair (K, V)**.
* Keys are used for grouping, reducing, or joining data.
* Values are the associated data items.

👉 Formally:

```
RDD[(K, V)]
```

where `K = key`, `V = value`.

---

## ⚡ Why Pair RDDs?

* They enable **distributed key-based operations**, like in **MapReduce**.
* Spark provides special transformations/actions optimized for Pair RDDs.

Examples:

* `reduceByKey()` → Combine values with the same key.
* `groupByKey()` → Group values by key.
* `join()` → Join two RDDs by key.
* `sortByKey()` → Sort by key.

---

## 📊 Example: Creating a Pair RDD

```python
from pyspark import SparkContext
sc = SparkContext("local", "PairRDDExample")

data = [("apple", 2), ("banana", 3), ("apple", 4)]
rdd = sc.parallelize(data)

print(rdd.collect())
```

**Output:**

```
[('apple', 2), ('banana', 3), ('apple', 4)]
```

Here, `rdd` is a **Pair RDD** with key = fruit, value = number.

---

## 📊 Example: `reduceByKey()`

Sum values for each key:

```python
result = rdd.reduceByKey(lambda a, b: a + b)
print(result.collect())
```

**Output:**

```
[('banana', 3), ('apple', 6)]
```

---

## 📊 Example: `groupByKey()`

Group values by key:

```python
grouped = rdd.groupByKey().mapValues(list)
print(grouped.collect())
```

**Output:**

```
[('banana', [3]), ('apple', [2, 4])]
```

---

## 📊 Example: `sortByKey()`

```python
sorted_rdd = rdd.sortByKey()
print(sorted_rdd.collect())
```

**Output:**

```
[('apple', 2), ('apple', 4), ('banana', 3)]
```

---

# 🖼️ Analogy

Think of a Pair RDD as a **phonebook** 📖:

* **Key** → Person’s name.
* **Value** → Phone number(s).

Operations like `reduceByKey()` = merging multiple phone numbers for the same person.

---

# 🔄 Summary

* Pair RDD = RDD of **(key, value)** pairs.
* Enables **special transformations** like `reduceByKey`, `groupByKey`, `join`, `sortByKey`.
* Widely used in **aggregation, joins, and distributed processing**.
