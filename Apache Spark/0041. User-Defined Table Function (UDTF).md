# ğŸ§© **What is a User-Defined Table Function (UDTF)?**

* A **UDTF** is a function that, instead of returning a **single value** like a scalar UDF, returns a **table (multiple rows and columns)**.
* They are useful when **one input row needs to be expanded into multiple output rows**.
* Common in **databases (Hive, SQL Server, PostgreSQL, etc.)** and supported in **Spark SQL** (from Spark 3.1+ using ANSI SQL standard).

ğŸ‘‰ Think of UDTFs as **functions that â€œexplodeâ€ data into new rows/columns**.

---

# âš¡ Difference from UDFs

* **UDF (User-Defined Function)** â†’ Returns a single value per row.
* **UDTF (User-Defined Table Function)** â†’ Returns multiple rows (a table) per row.

---

# ğŸ“Š Example in SQL: Splitting a String

Suppose you have a column with comma-separated values:

| id | tags         |
| -- | ------------ |
| 1  | spark,sql,ai |
| 2  | bigdata,ml   |

Using a UDTF `split_to_table(tags)`, you can expand:

| id | tag     |
| -- | ------- |
| 1  | spark   |
| 1  | sql     |
| 1  | ai      |
| 2  | bigdata |
| 2  | ml      |

---

# ğŸ—ï¸ **UDTF in Spark SQL (using `LATERAL VIEW`)**

Spark provides built-in UDTFs like **`explode()`**.

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split

spark = SparkSession.builder.appName("UDTFExample").getOrCreate()

data = [(1, "spark,sql,ai"), (2, "bigdata,ml")]
df = spark.createDataFrame(data, ["id", "tags"])

# Use explode (a UDTF) to split into multiple rows
df_exploded = df.select(df.id, explode(split(df.tags, ",")).alias("tag"))
df_exploded.show()
```

**Output:**

```
+---+-------+
| id|   tag |
+---+-------+
|  1|  spark|
|  1|    sql|
|  1|     ai|
|  2|bigdata|
|  2|     ml|
+---+-------+
```

ğŸ‘‰ Here, `explode(split(...))` is effectively a **UDTF**.

---

# ğŸ—ï¸ Defining Your Own UDTF (Custom Example in Spark 3.5+)

Spark 3.5 introduced **UDTFs in Python** (experimental). Example:

```python
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql.functions import udtf

# Define a UDTF
@udtf(returnType=StructType([StructField("word", StringType())]))
def split_words(s: str):
    for word in s.split(","):
        yield (word,)

# Use it
df = spark.createDataFrame([("a,b,c",), ("d,e",)], ["text"])
df.select(split_words("text")).show()
```

**Output:**

```
+----+
|word|
+----+
|   a|
|   b|
|   c|
|   d|
|   e|
+----+
```

---

# ğŸ–¼ï¸ Real-Life Use Cases of UDTFs

* ğŸ“Š **Exploding arrays/lists** into rows (e.g., tags, categories, JSON arrays).
* ğŸ¦ **Parsing text** (tweets â†’ multiple hashtags).
* ğŸŒ **URL parsing** (extract query params into rows).
* ğŸ” **Data enrichment** (splitting addresses, geocoding results).

---

# ğŸ–¼ï¸ Analogy

Think of UDTFs as a **machine that takes one input card ğŸ´ and prints multiple smaller cards**.

* **UDF** â†’ one card in, one card out.
* **UDTF** â†’ one card in, multiple cards out.

---

âœ… **Summary**

* **UDTFs return tables (multiple rows/columns)** instead of single values.
* Spark has **built-in UDTFs** (`explode`, `posexplode`, `inline`).
* **Custom UDTFs** are supported from **Spark 3.5 (experimental in Python)**.
* Great for **flattening, parsing, and expanding data**.
