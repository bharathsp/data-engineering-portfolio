# 🔑 **sortByKey() in Spark**

## 🧩 What is it?

* `sortByKey()` is an **RDD transformation** in Apache Spark.
* It is used on **Pair RDDs (key-value RDDs)**.
* It sorts the **RDD by keys** in either **ascending (default)** or **descending** order.

👉 It returns a **new RDD** where the data is sorted by the key.

---

## ⚡ Syntax

```python
rdd.sortByKey(ascending=True, numPartitions=None, keyfunc=lambda k: k)
```

### Parameters:

* `ascending`: `True` (default) for ascending, `False` for descending.
* `numPartitions`: Number of partitions in the output RDD.
* `keyfunc`: Function applied to keys before sorting (like a transformation on keys).

---

## 📊 Example 1: Basic Usage

```python
from pyspark import SparkContext
sc = SparkContext("local", "SortByKeyExample")

data = [(3, "apple"), (1, "banana"), (2, "cherry")]
rdd = sc.parallelize(data)

sorted_rdd = rdd.sortByKey()
print(sorted_rdd.collect())
```

**Output:**

```
[(1, 'banana'), (2, 'cherry'), (3, 'apple')]
```

---

## 📊 Example 2: Descending Order

```python
sorted_desc = rdd.sortByKey(ascending=False)
print(sorted_desc.collect())
```

**Output:**

```
[(3, 'apple'), (2, 'cherry'), (1, 'banana')]
```

---

## 📊 Example 3: Custom Key Function

Suppose keys are strings and you want to sort by **length of the key**:

```python
data = [("aa", 1), ("b", 2), ("ccc", 3)]
rdd = sc.parallelize(data)

sorted_custom = rdd.sortByKey(keyfunc=lambda k: len(k))
print(sorted_custom.collect())
```

**Output:**

```
[('b', 2), ('aa', 1), ('ccc', 3)]
```

---

# 🔄 Difference vs Similar Functions

* ✅ `sortByKey()` → Sorts by **key** (only for Pair RDDs).
* ✅ `sortBy()` → Can sort by **any function** applied to RDD elements.
* ✅ `orderBy()` → Used in **DataFrames**, not RDDs.

---

# 🖼️ Analogy

Think of `sortByKey()` like **sorting a dictionary by its keys** 📒 → you don’t care about values while sorting.

Example:

```
Before: {3: "apple", 1: "banana", 2: "cherry"}
After:  {1: "banana", 2: "cherry", 3: "apple"}
```

---

✅ **In short:**

* Use `sortByKey()` when working with **Pair RDDs**.
* It sorts based on the **keys** (ascending/descending).
* Useful in preprocessing, grouping, and ranking tasks in Spark.
